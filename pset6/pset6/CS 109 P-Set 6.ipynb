{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following arguments are not valid: {'C:\\\\Users\\\\Adonis-Surface Book\\\\AppData\\\\Roaming\\\\jupyter\\\\runtime\\\\kernel-51f04c4c-1fc7-4577-8420-01902507051e.json', '-f'}\n"
     ]
    }
   ],
   "source": [
    "# pylint: disable = missing-function-docstring\n",
    "'''\n",
    "Written by Tim Gianitsos\n",
    "CS 109 Probability for Computer Scientists, Fall 2019-2020, Winter 2019-2020\n",
    "Tested with Python 3.7.5\n",
    "\n",
    "*************************IMPORTANT*************************\n",
    "NOTE TO STUDENTS: You do NOT need to modify this file.\n",
    "Remember that you won't submit this file for autograding.\n",
    "All of your work should go in the files listed for\n",
    "submission on the assignment handout.\n",
    "\n",
    "For instructions on how to run the code in this file, see\n",
    "the README file in the starter code.\n",
    "*************************IMPORTANT*************************\n",
    "'''\n",
    "import sys\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import utils\n",
    "from naive_bayes import NaiveBayes\n",
    "from logistic_regression import LogisticRegression\n",
    "\n",
    "@utils.question_part(\n",
    "    classifier=NaiveBayes,\n",
    "    parameters={'use_max_like_estm': True},\n",
    "    dataset_name='simple',\n",
    "    expected={(0, 0, 0): 2, (1, 0, 0): 1, (1, 1, 0): 1, (0, 1, 1): 2, (1, 0, 1): 1, (1, 1, 1): 1},\n",
    "    message='Outputs the model the classifier learned from training'\n",
    ")\n",
    "def fit_bayes_simple(clf, train_features, train_labels, test_features, test_labels):\n",
    "    return fitting(clf, train_features, train_labels, test_features, test_labels)\n",
    "\n",
    "@utils.question_part(\n",
    "    classifier=NaiveBayes,\n",
    "    parameters={'use_max_like_estm': True},\n",
    "    dataset_name='netflix',\n",
    "    expected={\n",
    "        (0, 1, 1): 1497, (1, 1, 1): 1487, (2, 1, 1): 1325, (3, 1, 1): 1349, (4, 0, 1): 621,\n",
    "        (5, 1, 1): 1354, (6, 1, 1): 1341, (7, 0, 1): 679, (8, 1, 1): 1922, (9, 0, 1): 762,\n",
    "        (10, 1, 1): 1516, (11, 1, 1): 1476, (12, 1, 1): 1954, (13, 1, 1): 1498, (14, 1, 1): 1136,\n",
    "        (15, 1, 1): 1151, (16, 0, 1): 558, (17, 0, 1): 649, (18, 0, 1): 563, (0, 0, 0): 940,\n",
    "        (1, 0, 0): 718, (2, 0, 0): 736, (3, 0, 0): 779, (4, 0, 0): 981, (5, 1, 0): 1356,\n",
    "        (6, 1, 0): 1412, (7, 1, 0): 1361, (8, 1, 0): 1957, (9, 0, 0): 688, (10, 1, 0): 1507,\n",
    "        (11, 0, 0): 809, (12, 1, 0): 1987, (13, 1, 0): 1524, (14, 1, 0): 1286, (15, 1, 0): 1260,\n",
    "        (16, 1, 0): 1726, (17, 1, 0): 1287, (18, 0, 0): 1560, (2, 0, 1): 906, (4, 1, 1): 1610,\n",
    "        (5, 0, 1): 877, (6, 0, 1): 890, (9, 1, 1): 1469, (15, 0, 1): 1080, (18, 1, 1): 1668,\n",
    "        (7, 1, 1): 1552, (16, 1, 1): 1673, (17, 1, 1): 1582, (3, 1, 0): 1490, (7, 0, 0): 908,\n",
    "        (11, 1, 0): 1460, (18, 1, 0): 709, (1, 1, 0): 1551, (4, 1, 0): 1288, (5, 0, 0): 913,\n",
    "        (6, 0, 0): 857, (9, 1, 0): 1581, (16, 0, 0): 543, (1, 0, 1): 744, (2, 1, 0): 1533,\n",
    "        (13, 0, 0): 745, (11, 0, 1): 755, (13, 0, 1): 733, (15, 0, 0): 1009, (10, 0, 0): 762,\n",
    "        (17, 0, 0): 982, (14, 0, 0): 983, (8, 0, 0): 312, (0, 1, 0): 1329, (0, 0, 1): 734,\n",
    "        (3, 0, 1): 882, (10, 0, 1): 715, (14, 0, 1): 1095, (8, 0, 1): 309, (12, 0, 1): 277,\n",
    "        (12, 0, 0): 282\n",
    "    },\n",
    "    message='Outputs the model the classifier learned from training'\n",
    ")\n",
    "def fit_bayes_netflix(clf, train_features, train_labels, test_features, test_labels):\n",
    "    return fitting(clf, train_features, train_labels, test_features, test_labels)\n",
    "\n",
    "@utils.question_part(\n",
    "    classifier=NaiveBayes,\n",
    "    parameters={'use_max_like_estm': True},\n",
    "    dataset_name='ancestry',\n",
    "    message='Outputs the model the classifier learned from training'\n",
    ")\n",
    "def fit_bayes_ancestry(clf, train_features, train_labels, test_features, test_labels):\n",
    "    return fitting(clf, train_features, train_labels, test_features, test_labels)\n",
    "\n",
    "@utils.question_part(\n",
    "    classifier=NaiveBayes,\n",
    "    parameters={'use_max_like_estm': True},\n",
    "    dataset_name='heart',\n",
    "    message='Outputs the model the classifier learned from training'\n",
    ")\n",
    "def fit_bayes_heart(clf, train_features, train_labels, test_features, test_labels):\n",
    "    return fitting(clf, train_features, train_labels, test_features, test_labels)\n",
    "\n",
    "@utils.question_part(\n",
    "    classifier=LogisticRegression,\n",
    "    parameters={'learning_rate': 0.0001, 'max_steps': 10000},\n",
    "    dataset_name='simple',\n",
    "    expected=np.round([-0.14577434, 0.82004294, -0.06660849], 2),\n",
    "    message='Outputs the model the classifier learned from training'\n",
    ")\n",
    "def fit_logistic_simple(clf, train_features, train_labels, test_features, test_labels):\n",
    "    return fitting(clf, train_features, train_labels, test_features, test_labels)\n",
    "\n",
    "@utils.question_part(\n",
    "    classifier=LogisticRegression,\n",
    "    parameters={'learning_rate': 0.0001, 'max_steps': 3000},\n",
    "    dataset_name='netflix',\n",
    "    expected=np.round([\n",
    "        -1.26461287e+00, 1.46867021e-01, -3.21980376e-02, -1.92913294e-01,\n",
    "        -1.11223178e-01, 3.28113677e-01, 3.16795785e-02, -1.11730732e-01,\n",
    "        2.15760242e-01, -3.80626880e-02, -8.34949179e-02, 8.22010897e-02,\n",
    "        4.84433141e-02, 2.07252764e-02, 1.06403162e-03, -1.05318507e-01,\n",
    "        8.28210381e-03, -1.74354524e-02, 2.77574032e-01, 1.75611054e+00\n",
    "    ], 2),\n",
    "    message='Outputs the model the classifier learned from training'\n",
    ")\n",
    "def fit_logistic_netflix(clf, train_features, train_labels, test_features, test_labels):\n",
    "    print(train_labels.shape);\n",
    "    print(train_features.shape);\n",
    "    return fitting(clf, train_features, train_labels, test_features, test_labels)\n",
    "\n",
    "@utils.question_part(\n",
    "    classifier=LogisticRegression,\n",
    "    parameters={'learning_rate': 0.0001, 'max_steps': 10000},\n",
    "    dataset_name='ancestry',\n",
    "    message='Outputs the model the classifier learned from training'\n",
    ")\n",
    "def fit_logistic_ancestry(clf, train_features, train_labels, test_features, test_labels):\n",
    "    return fitting(clf, train_features, train_labels, test_features, test_labels)\n",
    "\n",
    "@utils.question_part(\n",
    "    classifier=LogisticRegression,\n",
    "    parameters={'learning_rate': 0.0001, 'max_steps': 10000},\n",
    "    dataset_name='heart',\n",
    "    message='Outputs the model the classifier learned from training'\n",
    ")\n",
    "def fit_logistic_heart(clf, train_features, train_labels, test_features, test_labels):\n",
    "    return fitting(clf, train_features, train_labels, test_features, test_labels)\n",
    "\n",
    "@utils.question_part(\n",
    "    classifier=NaiveBayes,\n",
    "    parameters={'use_max_like_estm': True},\n",
    "    dataset_name='simple',\n",
    "    expected=np.round(1.0, 2),\n",
    "    message='Percentage of correctly labeled answers:'\n",
    ")\n",
    "def predict_bayes_mle_simple(clf, train_features, train_labels, test_features, test_labels):\n",
    "    return predictions(clf, train_features, train_labels, test_features, test_labels)\n",
    "\n",
    "@utils.question_part(\n",
    "    classifier=NaiveBayes,\n",
    "    parameters={'use_max_like_estm': False},\n",
    "    dataset_name='simple',\n",
    "    expected=np.round(1.0, 2),\n",
    "    message='Percentage of correctly labeled answers:'\n",
    ")\n",
    "def predict_bayes_laplace_simple(clf, train_features, train_labels, test_features, test_labels):\n",
    "    return predictions(clf, train_features, train_labels, test_features, test_labels)\n",
    "\n",
    "@utils.question_part(\n",
    "    classifier=NaiveBayes,\n",
    "    parameters={'use_max_like_estm': True},\n",
    "    dataset_name='netflix',\n",
    "    message='Percentage of correctly labeled answers:'\n",
    ")\n",
    "def predict_bayes_mle_netflix(clf, train_features, train_labels, test_features, test_labels):\n",
    "    return predictions(clf, train_features, train_labels, test_features, test_labels)\n",
    "\n",
    "@utils.question_part(\n",
    "    classifier=NaiveBayes,\n",
    "    parameters={'use_max_like_estm': False},\n",
    "    dataset_name='netflix',\n",
    "    message='Percentage of correctly labeled answers:'\n",
    ")\n",
    "def predict_bayes_laplace_netflix(clf, train_features, train_labels, test_features, test_labels):\n",
    "    return predictions(clf, train_features, train_labels, test_features, test_labels)\n",
    "\n",
    "@utils.question_part(\n",
    "    classifier=NaiveBayes,\n",
    "    parameters={'use_max_like_estm': True},\n",
    "    dataset_name='ancestry',\n",
    "    message='Percentage of correctly labeled answers:'\n",
    ")\n",
    "def predict_bayes_mle_ancestry(clf, train_features, train_labels, test_features, test_labels):\n",
    "    return predictions(clf, train_features, train_labels, test_features, test_labels)\n",
    "\n",
    "@utils.question_part(\n",
    "    classifier=NaiveBayes,\n",
    "    parameters={'use_max_like_estm': False},\n",
    "    dataset_name='ancestry',\n",
    "    message='Percentage of correctly labeled answers:'\n",
    ")\n",
    "def predict_bayes_laplace_ancestry(clf, train_features, train_labels, test_features, test_labels):\n",
    "    return predictions(clf, train_features, train_labels, test_features, test_labels)\n",
    "\n",
    "@utils.question_part(\n",
    "    classifier=NaiveBayes,\n",
    "    parameters={'use_max_like_estm': True},\n",
    "    dataset_name='heart',\n",
    "    message='Percentage of correctly labeled answers:'\n",
    ")\n",
    "def predict_bayes_mle_heart(clf, train_features, train_labels, test_features, test_labels):\n",
    "    return predictions(clf, train_features, train_labels, test_features, test_labels)\n",
    "\n",
    "@utils.question_part(\n",
    "    classifier=NaiveBayes,\n",
    "    parameters={'use_max_like_estm': False},\n",
    "    dataset_name='heart',\n",
    "    message='Percentage of correctly labeled answers:'\n",
    ")\n",
    "def predict_bayes_laplace_heart(clf, train_features, train_labels, test_features, test_labels):\n",
    "    return predictions(clf, train_features, train_labels, test_features, test_labels)\n",
    "\n",
    "@utils.question_part(\n",
    "    classifier=LogisticRegression,\n",
    "    parameters={'learning_rate': 0.0001, 'max_steps': 10000},\n",
    "    dataset_name='simple',\n",
    "    expected=np.round(1.0, 2),\n",
    "    message='Percentage of correctly labeled answers:'\n",
    ")\n",
    "def predict_logistic_simple(clf, train_features, train_labels, test_features, test_labels):\n",
    "    return predictions(clf, train_features, train_labels, test_features, test_labels)\n",
    "\n",
    "@utils.question_part(\n",
    "    classifier=LogisticRegression,\n",
    "    parameters={'learning_rate': 0.0001, 'max_steps': 3000},\n",
    "    dataset_name='netflix',\n",
    "    message='Percentage of correctly labeled answers:'\n",
    ")\n",
    "def predict_logistic_netflix(clf, train_features, train_labels, test_features, test_labels):\n",
    "    return predictions(clf, train_features, train_labels, test_features, test_labels)\n",
    "\n",
    "@utils.question_part(\n",
    "    classifier=LogisticRegression,\n",
    "    parameters={'learning_rate': 0.0001, 'max_steps': 10000},\n",
    "    dataset_name='ancestry',\n",
    "    message='Percentage of correctly labeled answers:'\n",
    ")\n",
    "def predict_logistic_ancestry(clf, train_features, train_labels, test_features, test_labels):\n",
    "    return predictions(clf, train_features, train_labels, test_features, test_labels)\n",
    "\n",
    "@utils.question_part(\n",
    "    classifier=LogisticRegression,\n",
    "    parameters={'learning_rate': 0.0001, 'max_steps': 10000},\n",
    "    dataset_name='heart',\n",
    "    message='Percentage of correctly labeled answers:'\n",
    ")\n",
    "def predict_logistic_heart(clf, train_features, train_labels, test_features, test_labels):\n",
    "    return predictions(clf, train_features, train_labels, test_features, test_labels)\n",
    "\n",
    "#pylint:disable=unused-argument\n",
    "def fitting(clf, train_features, train_labels, test_features, test_labels):\n",
    "    clf.fit(train_features, train_labels)\n",
    "    return (\n",
    "        clf.feature_counts if isinstance(clf, NaiveBayes)\n",
    "        else clf.weights if isinstance(clf, LogisticRegression) else None\n",
    "    )\n",
    "\n",
    "def predictions(clf, train_features, train_labels, test_features, test_labels):\n",
    "    clf.fit(train_features, train_labels)\n",
    "    result_labels = clf.predict(test_features)\n",
    "    assert len(test_labels) == len(result_labels)\n",
    "    return (test_labels == result_labels).sum() / len(test_labels)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    utils.main(sys.argv[1:])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\tfit_logistic_netflix. Outputs the model the classifier learned from training\n",
      "(4500,)\n",
      "(4500, 19)\n",
      "(4500,)\n",
      "(4500,)\n",
      "PASSED\n",
      "\n",
      "\tpredict_logistic_netflix. Percentage of correctly labeled answers:\n",
      "(4500,)\n",
      "(4500,)\n",
      "HIDDEN (no runtime exceptions)\n",
      "result:   0.74\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.74"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fit_logistic_netflix()\n",
    "predict_logistic_netflix()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
